#!/bin/bash

# Neo4j Code Graph Analysis Pipeline
# Run this script to execute the complete analysis pipeline on any Git repository

set -e  # Exit on any error

# Check if repository URL is provided
if [ $# -eq 0 ]; then
    echo "âŒ Error: Repository URL required"
    echo ""
    echo "Usage: $0 <repository-url>"
    echo ""
    echo "Example:"
    echo "  $0 https://github.com/your-org/your-java-repo.git"
    echo ""
    exit 1
fi

REPO_URL=$1
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"

echo "ğŸš€ Starting Neo4j Code Graph Analysis Pipeline"
echo "=============================================="
echo "ğŸ“ Repository: $REPO_URL"
echo ""

# Step 0: Setup database schema and cleanup
echo "ğŸ—ï¸  Step 0: Setting up database schema..."
python "$SCRIPT_DIR/schema_management.py"
echo "âœ… Schema setup completed"

echo ""
echo "ğŸ§¹ Cleaning up previous analysis (if any)..."
python "$SCRIPT_DIR/cleanup_graph.py" --dry-run
read -p "Proceed with cleanup? (y/n): " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    python "$SCRIPT_DIR/cleanup_graph.py"
    echo "âœ… Cleanup completed"
else
    echo "âš ï¸  Skipping cleanup - you may have duplicate data"
fi

# Step 1: Clone Repository (once for efficiency)
echo ""
echo "ğŸ“¥ Step 1: Cloning repository for analysis..."
TEMP_REPO_DIR=$(mktemp -d)
git clone "$REPO_URL" "$TEMP_REPO_DIR"
echo "âœ… Repository cloned to: $TEMP_REPO_DIR"

# Cleanup function for proper temp directory removal
cleanup_repo() {
    if [ -n "$TEMP_REPO_DIR" ] && [ -d "$TEMP_REPO_DIR" ]; then
        echo "ğŸ§¹ Cleaning up temporary repository..."
        rm -rf "$TEMP_REPO_DIR"
        echo "âœ… Cleanup completed"
    fi
}

# Ensure cleanup on exit
trap cleanup_repo EXIT

# Step 2: Load Code Structure (Java files and methods with embeddings)
echo ""
echo "ğŸ“ Step 2: Loading Java code structure with embeddings..."
echo "â° This step may take a while for large repositories..."
python "$SCRIPT_DIR/code_to_graph.py" "$TEMP_REPO_DIR"
echo "âœ… Code structure loaded"

# Step 3: Load Git History (commits and developer data)
echo ""
echo "ğŸ“š Step 3: Loading Git commit history..."
python "$SCRIPT_DIR/git_history_to_graph.py" "$TEMP_REPO_DIR"
echo "âœ… Git history loaded"

# Step 4: Create Method Similarities  
echo ""
echo "ğŸ”— Step 4: Creating method similarities using KNN..."
python "$SCRIPT_DIR/create_method_similarity.py" --top-k 5 --cutoff 0.8
echo "âœ… Method similarities created"

# Step 5: Detect Communities
echo ""
echo "ğŸ˜ï¸  Step 5: Detecting communities using Louvain..."
python "$SCRIPT_DIR/create_method_similarity.py" --no-knn --community-threshold 0.8
echo "âœ… Communities detected"

# Step 6: Run Centrality Analysis
echo ""
echo "ğŸ¯ Step 6: Running centrality analysis to identify important methods..."
python "$SCRIPT_DIR/centrality_analysis.py" --algorithms pagerank betweenness degree --top-n 15 --write-back
echo "âœ… Centrality analysis completed"

# Step 7: Advanced Analysis
echo ""
echo "ğŸ”¥ Step 7: Running advanced analysis..."

echo "  ğŸ“Š Analyzing file change coupling..."
python "$SCRIPT_DIR/analyze.py" coupling --min-support 5 --create-relationships
echo "  âœ… Change coupling analysis completed"

echo "  ğŸ”¥ Analyzing code hotspots..."
python "$SCRIPT_DIR/analyze.py" hotspots --days 365 --min-changes 3 --top-n 15
echo "  âœ… Hotspot analysis completed"

# Step 8: Universal CVE Vulnerability Analysis
echo ""
echo "ğŸ›¡ï¸  Step 8: Universal vulnerability analysis..."
if [ -n "${NVD_API_KEY}" ] || [ -f ".env" ]; then
    echo "  ğŸ” Analyzing vulnerability impact using dynamic dependency extraction..."
    python "$SCRIPT_DIR/cve_analysis.py" --risk-threshold 7.0 --max-hops 4
    echo "  âœ… CVE analysis completed"
else
    echo "  âš ï¸  NVD_API_KEY not found - skipping CVE analysis"
    echo "  ğŸ’¡ To enable CVE analysis:"
    echo "     1. Get API key: https://nvd.nist.gov/developers/request-an-api-key"
    echo "     2. Add to .env: NVD_API_KEY=your_key_here"
fi

echo ""
echo "ğŸ‰ Pipeline completed successfully!"
echo "Your Neo4j graph now contains:"
echo ""
echo "ğŸ“ Core Structure:"
echo "  - Comprehensive code structure (Files, Methods, Classes, Interfaces, Directories)"
echo "  - Object-oriented relationships (EXTENDS, IMPLEMENTS, CONTAINS_METHOD)"
echo "  - Method call graph (CALLS relationships with call types)"
echo "  - Rich metadata (LOC, modifiers, complexity metrics)"
echo ""
echo "ğŸ“ˆ Temporal Analysis:"
echo "  - Complete Git history (Commits, Developers, File versions)"
echo "  - Change coupling analysis (CO_CHANGED relationships)"
echo "  - Multi-factor hotspot scoring (frequency Ã— complexity)"
echo ""
echo "ğŸ§  Semantic Analysis:"
echo "  - GraphCodeBERT embeddings (768-dimensional method similarity)"
echo "  - K-NN similarity networks with tunable similarity thresholds"
echo "  - Community detection via Louvain algorithm"
echo ""
echo "â­ Graph-Theoretic Insights:"
echo "  - PageRank centrality (overall importance in call graph)"
echo "  - Betweenness centrality (critical connectors and bottlenecks)"
echo "  - Degree centrality (hub methods and high-activity components)"
echo ""
echo "ğŸ›¡ï¸  Security Analysis:"
echo "  - Universal CVE vulnerability impact analysis"
echo "  - Language-agnostic dependency tracking"
echo "  - Multi-hop vulnerability propagation analysis"
echo ""
echo "ğŸ” Next Steps:"
echo "  1. Explore the graph via Neo4j Browser"
echo "  2. Run example queries from examples/ directory"
echo "  3. Build custom analyses using the rich graph structure"
echo ""
echo "ğŸ“Š For interactive CVE analysis, run:"
echo "     python examples/cve_demo_queries.py" 